\documentclass[11pt,a4paper,]{article}
\usepackage{lmodern}

\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\PassOptionsToPackage{hyphens}{url} % url is loaded by hyperref
\usepackage[unicode=true]{hyperref}
\PassOptionsToPackage{usenames,dvipsnames}{color} % color is loaded by hyperref
\hypersetup{
            pdftitle={Forecasting interrupted time series},
            pdfkeywords={blah, blah},
            colorlinks=true,
            linkcolor=blue,
            citecolor=Blue,
            urlcolor=Blue,
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{geometry}
\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}
\usepackage[style=authoryear-comp,]{biblatex}
\addbibresource{references.bib}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{long table}}{}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother


\title{Forecasting interrupted time series}

%% MONASH STUFF

%% CAPTIONS
\RequirePackage{caption}
\DeclareCaptionStyle{italic}[justification=centering]
 {labelfont={bf},textfont={it},labelsep=colon}
\captionsetup[figure]{style=italic,format=hang,singlelinecheck=true}
\captionsetup[table]{style=italic,format=hang,singlelinecheck=true}

%% FONT
\RequirePackage{bera}
\RequirePackage[charter,expert]{mathdesign}
\RequirePackage[scale=0.9]{sourcecodepro}
\RequirePackage[lf,t]{FiraSans}

%% HEADERS AND FOOTERS
\RequirePackage{fancyhdr}
\pagestyle{fancy}
\rfoot{\Large\sffamily\raisebox{-0.1cm}{\textbf{\thepage}}}
\makeatletter
\lhead{\textsf{\expandafter{\@title}}}
\makeatother
\rhead{}
\cfoot{}
\setlength{\headheight}{15pt}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\fancypagestyle{plain}{%
\fancyhf{} % clear all header and footer fields
\fancyfoot[C]{\sffamily\thepage} % except the center
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}}

%% MATHS
\RequirePackage{bm,amsmath}
\allowdisplaybreaks

%% GRAPHICS
\RequirePackage{graphicx}
\setcounter{topnumber}{2}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{4}
\renewcommand{\topfraction}{0.85}
\renewcommand{\bottomfraction}{0.85}
\renewcommand{\textfraction}{0.15}
\renewcommand{\floatpagefraction}{0.8}

%\RequirePackage[section]{placeins}

%% SECTION TITLES
\RequirePackage[compact,sf,bf]{titlesec}
\titleformat{\section}[block]
  {\fontsize{15}{17}\bfseries\sffamily}
  {\thesection}
  {0.4em}{}
\titleformat{\subsection}[block]
  {\fontsize{12}{14}\bfseries\sffamily}
  {\thesubsection}
  {0.4em}{}
\titlespacing{\section}{0pt}{*5}{*1}
\titlespacing{\subsection}{0pt}{*2}{*0.2}


%% TITLE PAGE
\def\Date{\number\day}
\def\Month{\ifcase\month\or
 January\or February\or March\or April\or May\or June\or
 July\or August\or September\or October\or November\or December\fi}
\def\Year{\number\year}

\makeatletter
\def\wp#1{\gdef\@wp{#1}}\def\@wp{??/??}
\def\jel#1{\gdef\@jel{#1}}\def\@jel{??}
\def\showjel{{\large\textsf{\textbf{JEL classification:}}~\@jel}}
\def\nojel{\def\showjel{}}
\def\addresses#1{\gdef\@addresses{#1}}\def\@addresses{??}
\def\cover{{\sffamily\setcounter{page}{0}
        \thispagestyle{empty}
        \placefig{2}{1.5}{width=5cm}{_extensions/numbats/wp/monash2}
        \placefig{16.9}{1.5}{width=2.1cm}{_extensions/numbats/wp/MBSportrait}
        \begin{textblock}{4}(16.9,4)ISSN 1440-771X\end{textblock}
        \begin{textblock}{7}(12.7,27.9)\hfill
        \includegraphics[height=0.7cm]{_extensions/numbats/wp/AACSB}~~~
        \includegraphics[height=0.7cm]{_extensions/numbats/wp/EQUIS}~~~
        \includegraphics[height=0.7cm]{_extensions/numbats/wp/AMBA}
        \end{textblock}
        \vspace*{2cm}
        \begin{center}\Large
        Department of Econometrics and Business Statistics\\[.5cm]
        \footnotesize http://monash.edu/business/ebs/research/publications
        \end{center}\vspace{2cm}
        \begin{center}
        \fbox{\parbox{14cm}{\begin{onehalfspace}\centering\Huge\vspace*{0.3cm}
                \textsf{\textbf{\expandafter{\@title}}}\vspace{1cm}\par
                \LARGE\@author\end{onehalfspace}
        }}
        \end{center}
        \vfill
                \begin{center}\Large
                \Month~\Year\\[1cm]
                Working Paper \@wp
        \end{center}\vspace*{2cm}}}
\def\pageone{{\sffamily\setstretch{1}%
        \thispagestyle{empty}%
        \vbox to \textheight{%
        \raggedright\baselineskip=1.2cm
     {\fontsize{24.88}{30}\sffamily\textbf{\expandafter{\@title}}}
        \vspace{2cm}\par
        \hspace{1cm}\parbox{14cm}{\sffamily\large\@addresses}\vspace{1cm}\vfill
        \hspace{1cm}{\large\Date~\Month~\Year}\\[1cm]
        \hspace{1cm}\showjel\vss}}}
\def\blindtitle{{\sffamily
     \thispagestyle{plain}\raggedright\baselineskip=1.2cm
     {\fontsize{24.88}{30}\sffamily\textbf{\expandafter{\@title}}}\vspace{1cm}\par
        }}
\def\titlepage{{\cover\newpage\pageone\newpage\blindtitle}}

\def\blind{\def\titlepage{{\blindtitle}}\let\maketitle\blindtitle}
\def\titlepageonly{\def\titlepage{{\pageone\end{document}}}}
\def\nocover{\def\titlepage{{\pageone\newpage\blindtitle}}\let\maketitle\titlepage}
\let\maketitle\titlepage
\makeatother

%% SPACING
\RequirePackage{setspace}
\spacing{1.5}

%% LINE AND PAGE BREAKING
\sloppy
\clubpenalty = 10000
\widowpenalty = 10000
\brokenpenalty = 10000
\RequirePackage{microtype}

%% PARAGRAPH BREAKS
\setlength{\parskip}{1.4ex}
\setlength{\parindent}{0em}

%% HYPERLINKS
\RequirePackage{xcolor} % Needed for links
\definecolor{darkblue}{rgb}{0,0,.6}
\RequirePackage{url}

\makeatletter
\@ifpackageloaded{hyperref}{}{\RequirePackage{hyperref}}
\makeatother
\hypersetup{
     citecolor=0 0 0,
     breaklinks=true,
     bookmarksopen=true,
     bookmarksnumbered=true,
     linkcolor=darkblue,
     urlcolor=blue,
     citecolor=darkblue,
     colorlinks=true}

%% KEYWORDS
\newenvironment{keywords}{\par\vspace{0.5cm}\noindent{\sffamily\textbf{Keywords:}}}{\vspace{0.25cm}\par\hrule\vspace{0.5cm}\par}

%% ABSTRACT
\renewenvironment{abstract}{\begin{minipage}{\textwidth}\parskip=1.4ex\noindent
\hrule\vspace{0.1cm}\par{\sffamily\textbf{\abstractname}}\newline}
  {\end{minipage}}


\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage[showonlyrefs]{mathtools}
\usepackage[no-weekday]{eukdate}

%% BIBLIOGRAPHY

\makeatletter
\@ifpackageloaded{biblatex}{}{\usepackage[style=authoryear-comp, backend=biber, natbib=true]{biblatex}}
\makeatother
\ExecuteBibliographyOptions{bibencoding=utf8,minnames=1,maxnames=3, maxbibnames=99,dashed=false,terseinits=true,giveninits=true,uniquename=false,uniquelist=false,doi=false, isbn=false,url=true,sortcites=false, date=year}

\DeclareFieldFormat{url}{\texttt{\url{#1}}}
\DeclareFieldFormat[article]{pages}{#1}
\DeclareFieldFormat[inproceedings]{pages}{\lowercase{pp.}#1}
\DeclareFieldFormat[incollection]{pages}{\lowercase{pp.}#1}
\DeclareFieldFormat[article]{volume}{\mkbibbold{#1}}
\DeclareFieldFormat[article]{number}{\mkbibparens{#1}}
\DeclareFieldFormat[article]{title}{\MakeCapital{#1}}
\DeclareFieldFormat[inproceedings]{title}{#1}
\DeclareFieldFormat{shorthandwidth}{#1}
% No dot before number of articles
\usepackage{xpatch}
\xpatchbibmacro{volume+number+eid}{\setunit*{\adddot}}{}{}{}
% Remove In: for an article.
\renewbibmacro{in:}{%
  \ifentrytype{article}{}{%
  \printtext{\bibstring{in}\intitlepunct}}}

\makeatletter
\DeclareDelimFormat[cbx@textcite]{nameyeardelim}{\addspace}
\makeatother
\renewcommand*{\finalnamedelim}{%
  %\ifnumgreater{\value{liststop}}{2}{\finalandcomma}{}% there really should be no funny Oxford comma business here
  \addspace\&\space}

\wp{no/yr}
\jel{C10,C14,C22}

\RequirePackage[absolute,overlay]{textpos}
\setlength{\TPHorizModule}{1cm}
\setlength{\TPVertModule}{1cm}
\def\placefig#1#2#3#4{\begin{textblock}{.1}(#1,#2)\rlap{\includegraphics[#3]{#4}}\end{textblock}}


\nocover

\author{Bahman~Rostami-Tabar, Rob J~Hyndman}
\addresses{\textbf{Bahman Rostami-Tabar}\newline
Cardiff Business School\newline
Wales CF10 3EU\newline
United Kingdom\newline
{Email: rostami-tabarb@cardiff.ac.uk}\newline Corresponding author\newline\\[0.5cm]
\textbf{Rob J Hyndman}\newline
Department of Econometrics \& Business Statistics\newline
Monash University\newline
Clayton VIC 3800\newline
Australia\newline
{Email: Rob.Hyndman@monash.edu}\\[0.5cm]
}

\date{\sf\Date~\Month~\Year}
\makeatletter
 \lfoot{\sf Rostami-Tabar, Hyndman: \@date}
\makeatother

\usepackage[section]{placeins}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

% Adjust headwidth in case user has changed geometry in header-includes
\renewcommand{\headwidth}{\textwidth}

\begin{document}
\maketitle
\begin{abstract}
A brief summary of our ideas
\end{abstract}
\begin{keywords}
blah, blah
\end{keywords}

\section{Introduction}\label{introduction}

Time series are sometimes interrupted by unusual events; for example, a
natural disaster may occur, or a there may be a temporary policy change.
Many forecasters have faced this issue recently with the COVID-19
pandemic, where historical patterns have been severely disrupted due to
lockdowns and other restrictions. In this paper, we consider the problem
of forecasting during such an event, and after it has occurred.

This is a different problem from change point detection. In the
situations we consider, we know that a change has occurred, and we want
to forecast the future after the change. Change point detection is about
identifying \emph{when} a change has occurred.

Time series models usually assume that the data evolve in the future in
a similar way to how they have evolved in the past. But a big event
(such as COVID-19) can result in a future that is different from the
past, at least in the short term.

The disruption may result in relatively simple changes in the series;
for example a level shift at the start of the disruption, and another at
the end of the disruption. Or they may be more complex, with changes to
the seasonal patterns, and changes to the level, which evolve over time.
In this paper, we consider a range of models that can be used to handle
such changes, and compare their performance on some real data sets.

We introduce several approaches to handling interruptions when
forecasting in Section~\ref{sec-methods}. We then apply these approaches
to two real data sets in \textbf{?@sec-sec-examples}. Finally, in
\textbf{?@sec-conclusions}, we discuss some of the advantages and
disadvantages of each approach, and provide some recommendations for
practitioners.

\section{Handling interruptions when forecasting}\label{sec-methods}

We consider several possible ways to handle interruptions when
forecasting.

\subsection{Use a highly adaptive
model}\label{use-a-highly-adaptive-model}

Highly adaptive models can adjust to the interruption as it is
happening, and will therefore be able to approximate the data generating
process relatively well. For example, an ETS model with large smoothing
parameters will be able to adjust to the interruption relatively
quickly. This has the advantage of being a very simple solution that is
easy to implement and fast to compute. There is no need to explicitly
model the interruption, and so the model can be used for forecasting
even if the timing or effect of the interruption is unknown.

However, the prediction intervals will be large, because the model will
have heavily discounted past data. In fact, the model will largely
forget the past data other than the most recent observations, so there
is no memory of the seasonal patterns and other dynamics that were
present before the interruption. Consequently, the approach works best
if there is no assumption that the post-interruption period will be
similar to the pre-interruption period.

\subsection{Use an intervention model}\label{use-an-intervention-model}

A dynamic regression model with intervention covariates can be used to
model the interruption explicitly. For example, if the intervention
involves a simple level shift, with a reverse level shift at the end of
the intervention, we can use a dummy variable to indicate the
interruption period, and allow the model to adjust to the interruption.
More complicated interventions can be handled by using more covariates.

This has the advantage of retaining the memory of the past, and so the
seasonal patterns and other dynamics will be retained. This allows the
change period to be effectively modelled provided the intervention
variables are chosen well. However, the model will assume that the
post-interruption period will be similar to the pre-interruption period,
and so the prediction intervals may be be too narrow, especially if
there is a lasting effect beyond the end of the interruption.

\subsection{Treat the interruption period as
missing}\label{treat-the-interruption-period-as-missing}

Many time series models will handle periods of missing values. So the
problematic observations that occur during the period of disruption can
be set to missing, and the model should continue to produce forecasts as
if the interruption had not occurred. Of course, the forecasts will not
be accurate for the period of disruption, but they can be interpreted as
``what might have been''. This solution requires a judgement to be made
about when the disruption has begun, and when normality resumes.

Because no information is retained during the disruption, the prediction
intervals will become large during the disruption, and after the
disruption they will remain large until the model has enough data to
estimate the forecast distribution more accurately.

\subsection{Estimate what might have
been}\label{estimate-what-might-have-been}

A fourth solution is to estimate what might have been during the period
of disruption, and then use the adjusted data to fit a model. The
estimates could be made using any convenient method. One approach would
be to set the estimates to equal the forecasts made using only
pre-interruption data. This then becomes almost equal to the previous
solution except that the prediction intervals will be narrower because
the estimation uncertainty has not been taken into account. On the other
hand, it is more flexible than the previous approach because models that
do not handle missing values can then be used.

An alternative would be to take the model estimated under the previous
solution (setting the observations during the disruption to missing),
and use it to estimate what might have been during the disruption. Then
the model can be re-estimated using the adjusted data. Note that
forecasts obtained in this way during the disruption will not be true
forecasts, because they will have used data from the future in computing
the adjusted data during the disruption. But post-disruption forecasts
will be true forecasts, and should be almost the same as those obtained
using the previous solution.

\subsection{Downweight the interruption
period}\label{downweight-the-interruption-period}

Intuitively, we want the model to be more influenced by the patterns
observed before the disruption period than those during the disruption,
but we still want to take some account of the observations during the
disruption period.

Using this weighting approach, we can leverage the insights from the
pre-disruptive period while still accounting for the disruptive period's
influence. It allows the model to better capture the underlying dynamics
of the time series in non-disrupted periods, which may be essential for
accurate forecasting in the post-disruption era.

If the weights during the disruption are set to zero, and the weights at
other times are set to 1, this becomes equivalent to the missing value
solution above. Rather than ignoring the data during the disruption, the
weighting approach allows the model to not be completely blind to the
disruption's effects, and adapt to changes or shifts in the time series
caused by the event.

While conceptually simple to implement, in practice, this approach may
require more work than the other methods discussed here as most
forecasting software does not allow for the explicit use of weights.

\subsection{Ensemble models}\label{ensemble-models}

As with may forecasting problems, taken an ensemble approach often leads
to more accurate forecasts \autocite{combinations}. Here, we could
combine some or all four of the approaches discussed above to obtain an
ensemble forecast. In fact, if we were unable to implement the weighted
approach, by using an ensemble of the other approaches we are
effectively downweighting the observations during the disruption period
as they are only explicitly used in the first two approaches (using a
highly adaptive model, or using an intervention model).

However, a disadvantage of this approach is that it is averaging
forecasts that aim to achieve different objectives. For example, the
highly adaptive model and the intervention model are trying to forecast
what happened during the disruption, while the missing value and
estimation approaches are trying to forecast what might have happened.
So the ensemble approach will lie somewhere between these two
objectives.

\section{Examples}\label{sec-examples}

Let's consider some examples to data observed during the last few years,
where the effect of the COVID-19 pandemic has been particularly evident.

\subsection{Australian tourism}\label{sec-tourism}

The Australian tourism data set is a monthly time series showing the
number of short-term overseas visitors to Australia. The data
\autocite{tourismdata} are available from January 2000 to May 2023, and
are shown in Figure~\ref{fig-tourism-plot1}. As the borders closed in
March 2020, the number of visitors to Australia dropped to near zero,
and remained there until towards the end of 2021. The borders officially
reopened on 21 February 2022, although it seems visitors began to arrive
earlier than that.

\begin{figure}

\centering{

\includegraphics{fits_files/figure-pdf/fig-tourism-plot1-1.pdf}

}

\caption{\label{fig-tourism-plot1}Short-term visitor arrivals to
Australia (monthly): Jan 2000 -- May 2023.}

\end{figure}%

We apply the first four solutions discussed in the previous section to
these data, making 12 month forecasts at the end of each year from 2019
to 2022. We fit ETS, ARIMA and dynamic ARIMA models to the data
\autocite{fpp3}, first applying a log transformation to ensure the
resulting forecasts are positive. This is possible, because the
observations never reach exactly zero, with the smallest number of
visitors per month equal to 2250 in April 2020. For all forecasts, we
also show 90\% prediction intervals.

\begin{figure}[t]

\centering{

\includegraphics{fits_files/figure-pdf/fig-tsol1-plot-1.pdf}

}

\caption{\label{fig-tsol1-plot}Solution 1. Forecasts from ETS and ARIMA
models. Neither works particularly well for disruptions of this
magnitude.}

\end{figure}%

In Figure~\ref{fig-tsol1-plot}, we show forecasts by applying ETS and
ARIMA models to the data. ETS, in particular, is well-known to be
relatively adaptive to changes in the series, and this is evident in
these forecasts. The forecasts for 2020 were made using data before
COVID-19 had any affect, and so they show similar patterns to the past.
The forecasts for 2021 were made after 9 months of very low levels of
arrivals, and both models show forecasts consistent with the recent
history. The use of logarithms is particularly important here as the
variance is much smaller during 2020 than previously, but after taking
logarithms, the variance is more stable over time. The forecasts made at
the start of 2022 have struggled to detect the small increase in traffic
at the end of 2021, and both models have forecast relatively flat
trajectories as a result, although the prediction intervals are wide
indicating model uncertainty. Finally, the forecasts made at the end of
2022 have captured the increasing trend, but ETS is much closer to the
reality, adapting more quickly to the changing patterns. Again, the wide
prediction intervals indicate a high level of uncertainty. It is
possible to make ETS more adaptive to changes in the data by increasing
the value of the smoothing parameters. For example, a high value of
\(\beta\) (the smoothing parameter for the slope), will result in
changes of trend being incorporated into the forecasts more quickly, at
the risk of over-reacting to noise in the data, and increasing the size
of the prediction intervals even more.

\begin{figure}[b]

\centering{

\includegraphics{fits_files/figure-pdf/fig-tsol2-plot-1.pdf}

}

\caption{\label{fig-tsol2-plot}Solution 2. We use a level shift from
March 2020 to October 2022, and a ramp from October 2021 to October
2022. After October 2022, all intervention variables are set to zero.}

\end{figure}%

Figure~\ref{fig-tsol2-plot} shows forecasts obtained using a dynamic
regression model (i.e., a regression with ARIMA errors) using two
intervention variables: a level shift from March 2022 to November 2022,
and a ramp from October 2021 to November 2022. It is evident that the
level shift variable has worked well, giving relatively good forecasts
for 2021. However, the forecasts for 2022 are particularly poor, because
the ramp slope has been greatly overestimated, as it was based on only
three observations (Oct -- Dec 2021). The forecasts for 2023 are much
better, and the relatively large prediction intervals are appropriate
given the uncertainty in the industry at the end of 2022.

\begin{figure}[b]

\centering{

\includegraphics{fits_files/figure-pdf/fig-tsol3-plot-1.pdf}

}

\caption{\label{fig-tsol3-plot}Solution 3. The period from March 2020 to
October 2022 is set to missing. So the first three years of forecasts
show what might have been. The fourth set of forecasts uses observations
from November and December 2022, and so the forecasts have been adjusted
downwards.}

\end{figure}%

The third solution (Figure~\ref{fig-tsol3-plot}) involved setting the
observations during the disruption period to missing, and then fitting
an ARIMA model to the series. Consequently, the first three years of
forecasts show what might have been without the COVID-19 pandemic, based
on the history to the end of 2019. The final forecasts for 2023 use the
data to the end of 2019, and the two observations in November and
December 2022. These are much better, but the prediction intervals are
too narrow, as there hasn't been sufficient recent data.

\begin{figure}[!b]

\centering{

\includegraphics{fits_files/figure-pdf/fig-tsol4-plot-1.pdf}

}

\caption{\label{fig-tsol4-plot}Solution 4. We replace the observations
from March 2020 to October 2022 with the average of the same month in
the three years prior to March 2020.}

\end{figure}%

We show in Figure~\ref{fig-tsol4-plot} the forecasts obtained using
solution 4. Here we have replaced observations between March 2020 and
October 2022 with estimates based on the average of the same month in
the three years prior to March 2020. The resulting forecasts are similar
to those from solution 3, but with narrower prediction intervals because
the model is (falsely) assuming that the ``observations'' during the
disruption are real.

Finally, in Figure~\ref{fig-tensemble-plot}, we show the ensemble
forecasts obtained by averaging the forecasts from the four solutions
discussed above. The first and fourth solutions carry double weight,
because both the ETS and ARIMA forecasts were included in the ensemble.
This time, no prediction intervals have been computed. The first set of
forecasts have not taken any account of the disruption, and so are
almost identical to those obtained in the previous plots. The last set
of forecasts are reasonably good, showing what is obtained by combining
the forecasting methods used to handle the disruption period. However,
the forecasts for 2021 and 2022 are particularly poor, because they are
averaging forecasts that aim to achieve different objectives, and are
affected by the poor forecasts obtained using the dynamic regression
model.

\begin{figure}[t]

\centering{

\includegraphics{fits_files/figure-pdf/fig-tensemble-plot-1.pdf}

}

\caption{\label{fig-tensemble-plot}Ensemble solution, combining the
previous four approaches shown in Figures
\ref{fig-tsol1-plot}--\ref{fig-tsol4-plot}.}

\end{figure}%

\FloatBarrier

\subsection{Example: Pedestrians}\label{example-pedestrians}

The pedestrian data set is a daily time series showing the number of
pedestrians per day in Melbourne, Australia. The data were obtained from
the Pedestrian Counting System maintained by the City of Melbourne
\autocite{pedestrians}, and are based on automated hourly counts from
sensors at 66 locations over the period from 2019-01-01 to 2021-12-31.
All sensors had some missing data, and we chose to use sensors with no
more than 720 missing hours, equivalent to 30 days of missing data. This
resulted in 25 sensors being used in the analysis. The data were
aggregated to daily counts for each sensor, and then the results were
averaged across sensors to obtain a measure of pedestrian traffic per
day. The resulting time series is shown in Figure~\ref{fig-walkers}.

\begin{figure}

\centering{

\includegraphics{fits_files/figure-pdf/fig-walkers-1.pdf}

}

\caption{\label{fig-walkers}Pedestrian traffic in Melbourne, Australia,
from 2018 to 2023. The gray shaded regions indicate periods of lockdown
due to COVID-19.}

\end{figure}%

We have also shown the periods of lockdown due to COVID-19. In
Melbourne, there were six separate lockdowns ranging from 5 days to 111
days in length. The first official lockdown period was from 31 March
2020 to 12 May 2020, and the last lockdown was from 05 Aug 2021 to 21
Oct 2021. However, the first period was preceded by over a week when
most people elected to stay and work at home, so we have chosen to start
the first period on 23 Mar 2020, to better reflect human behaviour.
Otherwise, we have used the official lockdown dates
\autocite{MelbourneLockdowns}.

We evaluate the solutions discussed in Section~\ref{sec-methods} by
using time series cross-validation, with the initial training set
comprising the whole of 2019, and subsequent training sets growing by 1
week at a time, to the end of 2021. The test sets are always 1 week
long. Thus, we have evaluated the forecasts during 2020 and 2021,
covering all lockdown periods, and the start of the recovery period. No
transformations of the data have been used. The results are shown in
Figures \ref{fig-walkers-plot1}--\ref{fig-walkers-plot4}. Prediction
intervals have not been shown to avoid cluttering the plots.

\begin{figure}

\centering{

\includegraphics{fits_files/figure-pdf/fig-walkers-plot1-1.pdf}

}

\caption{\label{fig-walkers-plot1}Solution 1: the forecasts do not take
into account the lockdown periods, but the ARIMA model is largely able
to adjust to the changing level of the series.}

\end{figure}%

We use ARIMA models in Figure~\ref{fig-walkers-plot1}, which have mostly
been able to adapt to the changing level of the series, apart from
during the first few weeks of the first lockdown, and the first day or
two of subsequent lockdowns.

In Figure~\ref{fig-walkers-plot2}, we have used an intervention model,
with a dummy variable indicating the lockdown periods. This has worked a
little better than the ARIMA model used in
Figure~\ref{fig-walkers-plot1}, apart from around the first lockdown
period. Many people were in self-imposed lockdown before the start of
the first lockdown period, and were reluctant to return to the city
after it ended, resulting in poor forecasts on either side of the first
lockdown.

\begin{figure}

\centering{

\includegraphics{fits_files/figure-pdf/fig-walkers-plot2-1.pdf}

}

\caption{\label{fig-walkers-plot2}Solution 2: the forecasts are based on
an ARIMA model with a dummy variable indicating when the lockdown
periods occurred. Many people were in self-imposed lockdown before the
start of the first lockdown period, and were reluctant to return to the
city after it ended, resulting in poor forecasts on either side of the
first lockdown. The model was able to adjust to the changing level of
the series during subsequent lockdowns.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics{fits_files/figure-pdf/fig-walkers-plot3-1.pdf}

}

\caption{\label{fig-walkers-plot3}Solution 3: the lockdown periods are
set to missing, and the ARIMA model uses the remaining data to produce
forecasts. Thus, the forecasts are based on only previous non-lockdown
data. Naturally, the forecasts during the lockdown periods do not
reflect reality, but they can be interpreted as what might have been.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics{fits_files/figure-pdf/fig-walkers-plot4-1.pdf}

}

\caption{\label{fig-walkers-plot4}Solution 4: the lockdown periods are
replaced with estimated counts based on an ARIMA model applied to the
remaining data. Then a new ARIMA model is fitted to the whole data set,
and used to produce forecasts. As a result, the forecasts during the
lockdown periods are not true forecasts, as they use non-lockdown data
from the future.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics{fits_files/figure-pdf/fig-walkers-ensemble-plot-1.pdf}

}

\caption{\label{fig-walkers-ensemble-plot}Ensemble forecasts based on
the first two solutions shown in Figures \ref{fig-walkers-plot1} and
\ref{fig-walkers-plot2}. Other than having some difficulty around the
period of the first lockdown, the results are relatively good.}

\end{figure}%

Figure~\ref{fig-walkers-plot3} shows the results obtained by setting the
observations during the lockdown periods to missing, and then fitting an
ARIMA model to the remaining data. The forecasts during lockdowns show
what might have been if that particular lockdown hadn't occurred, based
on previous non-lockdown data.

The forecasts shown in Figure~\ref{fig-walkers-plot4} are obtained by
replacing the observations during the lockdown periods with estimates
based on an ARIMA model applied to the remaining data. Then a new ARIMA
model is fitted to the whole data set, and used to produce forecasts. As
a result, the ``forecasts'' appear to interpolate across the lockdown
periods, reflecting neither the true lockdown pattern, or the pattern
that might have occurred without the lockdowns.

Finally, in Figure~\ref{fig-walkers-ensemble-plot}, we show the ensemble
forecasts obtained by averaging the forecasts from the first two
solutions discussed above. The results are relatively good, other than
having some difficulty around the period of the first lockdown.

\section{Discussion}\label{discussion}

We have presented several approaches to forecasting in the presence of
an interruption. Each has its advantages and disadvantages, and the
choice of which to use will depend on the situation. In fact, we have
used almost all of these approaches in our own consulting work. An
intervention model is often a good solution, provided the intervention
can be modelled relatively simply. However, if the intervention is
complex, then a highly adaptive method is often better. The highly
adaptive model is also useful when the timing of the interruption is
unknown, or when the post-interruption period is expected to be very
different from the pre-interruption period. The missing value approach
is particularly useful when only post-interruption forecasts are
required, and forecasts during the interruption period are not needed.

We have not previously used the weighted approach in practice, and
software to implement it is not currently available. However, it seems
to be a good compromise between the highly adaptive model and the
intervention model, and we expect it to be useful in many situations,
once software is available to implement it easily.

Finally, the ensemble approach is useful when there is uncertainty about
which approach to use, and will often result in greater accuracy due the
power of averaging.

We have not discussed probabilistic forecasting in any detail in this
paper, other than producing some prediction intervals for some of the
examples. One would expect forecast uncertainty to increase during, and
to some extent after, a major disruption. The highly adaptive model and
innovation model should produce relatively good prediction intervals,
although the variance is often underestimated. Because the missing value
approach is producing counterfactual (``what might have been'')
forecasts, the prediction intervals will often not include the actual
observations during the disruption period. Prediction intervals for
ensemble forecasts can be obtained by averaging the end points of the
component prediction intervals, for those models where the prediction
intervals seem reasonable.

\printbibliography[title=References]

\end{document}
